{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebc0dcf3",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfeaa047",
   "metadata": {},
   "source": [
    "1. Confusion matrix is a N * N matrics used for evaluation performance of claasification model.\n",
    "2. Where N is the number of target values\n",
    "3. Matrics compare the actual target values with those predicted by machine learning model\n",
    "4. For Binary classification Pattern, we have used 2 * 2 matrix\n",
    "5. Columns [represent the actual values of a target variable]\n",
    "6. Row [Represent the Predicted values of target variable]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d160b1",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/667/1*3yGLac6F4mTENnj5dBNvNQ.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b06253c",
   "metadata": {},
   "source": [
    "1. TP [True Positive]:\n",
    "    1. Predicted value matches the actual values\n",
    "    2. Actual value was Positive and Model predict as Positive Value\n",
    "2. TN [True Negative]:\n",
    "    1. Predicted value matches actual values\n",
    "    2. Actual value was Negative and Model predict as Negative values\n",
    "3. FP[False Positive - Type 1 Error]:\n",
    "    1. Predicted value was falsly Predicted\n",
    "    2. Actual value was Nagative but our Model predicted as Positive\n",
    "    1. This is also called as type 1 Error\n",
    "4. FN[False Negative - Type 2 Error]:\n",
    "    1. Predicted value was Falsly Predicted\n",
    "    2. Actual value was Positive but our Model predicted as Negative.\n",
    "    3. This is also called as Type 2 Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1578e814",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cbe083",
   "metadata": {},
   "source": [
    "**Accuracy = TP + TN / TP + FP + FN + TN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55d63647",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 74\n",
    "TN = 43\n",
    "FP = 8\n",
    "FN = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55b0a682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.81818181818183"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "117 / 143 * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9989c880",
   "metadata": {},
   "source": [
    "## Classification Report "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536f3b2d",
   "metadata": {},
   "source": [
    "1. Precision:\n",
    "    1. Precision tell us how many of the correctly predicted cases actually turned out to be positive\n",
    "    2. Precision is useful matrix in case where false Positive is a higer common then false Higher\n",
    "    **3. Formula = Precision = TP / TP + FP**\n",
    "2. Recall:\n",
    "    1. Recall tell us how many of the actual Positive cases we were also to predicted with our model\n",
    "    2. Recall is a useful metrix is useful where false Negative turns into a False Positive\n",
    "    **3. Formula - Recall = TP / TP + FN**\n",
    "3. F1 Score:\n",
    "    1. Try to increase the prediction of our model, recall goes down, and vice versa, F1 score capture trends in  a single value\n",
    "    **2. Formula - F1-Score = 2 / (1/ Precision) + (1/Recall)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca54be0b",
   "metadata": {},
   "source": [
    "1. Recall is important in medical cases where it dosent matter whether we rated a false alarm but the actual Positive cases should not to undetected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ee6a68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
